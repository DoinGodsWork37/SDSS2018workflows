Data Science Workflows
========================================================
author: Jim Harner
date: 5/6/18
autosize: true

## Symposium on Data Science and Statistics
### Reston, Virginia
### May 16--19, 2018

The Data Science Process
========================================================

The data science workflow or process starts with data extraction and end with a data produce. A common version of this process is illustrated by:   

![The Data Science Process](workflows-figure/dsciProcess.png)  

This diagram is taken from [Doing Data Science](http://shop.oreilly.com/product/0636920028529.do). Notice the flow along the top where data is collected, processed, cleaned, and explored. Many conflate data science with the box on the right, i.e., machine learning algorithms and statistical models, but it is much more that that. Ultimately, we want to make decisions or to create data products, an iterative process.

Hadley's Tidyverse
=======================================================

Hadley Wickham has a more abbreviated and specific version given here: [R for Data Science](http://r4ds.had.co.nz/introduction.html#what-you-will-learn).

It focuses on:

- `tidyr` to make data tidy,
- `dplyr` for transforming the data,
- `ggplot2` for visualization, and others.

A Dockerized versions of R called <[rocker](http://github.com/rocker-org/rocker)> is available.  The Docker image `verse` adds the `rstudio`, `tidyverse`, and `verse` layers to the `r-ver` base image. The tidyverse can be spun up with the following bash command:
```
sudo docker run -p 8787:8787 rocker/verse
```

Rspark
======================================================

`rspark` extends `rocker` to the Spark ecosystem. The GitHub repo for `rspark` can be found [here](http://github.com/jharner/rspark). `rspark` consists of containers for RStudio, PostgreSQL, Hadoop, Hive, and Spark. By default, Spark has a master and two workers although it can also be run within the RStudio container as an option.






